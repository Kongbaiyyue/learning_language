{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x23cb84c6410 state=finished raised AuthenticationError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\lenovo\\.conda\\envs\\openai\\lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\.conda\\envs\\openai\\lib\\site-packages\\openai\\embeddings_utils.py:23\u001b[0m, in \u001b[0;36mget_embedding\u001b[1;34m(text, engine, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m \u001b[39mreturn\u001b[39;00m openai\u001b[39m.\u001b[39mEmbedding\u001b[39m.\u001b[39mcreate(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39m[text], engine\u001b[39m=\u001b[39mengine, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\.conda\\envs\\openai\\lib\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     35\u001b[0m     \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[39m# This is only for the default case.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\.conda\\envs\\openai\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:149\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[0;32m    141\u001b[0m         timeout,\n\u001b[0;32m    142\u001b[0m         stream,\n\u001b[0;32m    143\u001b[0m         headers,\n\u001b[0;32m    144\u001b[0m         request_timeout,\n\u001b[0;32m    145\u001b[0m         typed_api_type,\n\u001b[0;32m    146\u001b[0m         requestor,\n\u001b[0;32m    147\u001b[0m         url,\n\u001b[0;32m    148\u001b[0m         params,\n\u001b[1;32m--> 149\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m__prepare_create_request(\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[0;32m    153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\.conda\\envs\\openai\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:106\u001b[0m, in \u001b[0;36mEngineAPIResource.__prepare_create_request\u001b[1;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    104\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m MAX_TIMEOUT\n\u001b[1;32m--> 106\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39;49mAPIRequestor(\n\u001b[0;32m    107\u001b[0m     api_key,\n\u001b[0;32m    108\u001b[0m     api_base\u001b[39m=\u001b[39;49mapi_base,\n\u001b[0;32m    109\u001b[0m     api_type\u001b[39m=\u001b[39;49mapi_type,\n\u001b[0;32m    110\u001b[0m     api_version\u001b[39m=\u001b[39;49mapi_version,\n\u001b[0;32m    111\u001b[0m     organization\u001b[39m=\u001b[39;49morganization,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    113\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\.conda\\envs\\openai\\lib\\site-packages\\openai\\api_requestor.py:134\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[1;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m api_base \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_base\n\u001b[1;32m--> 134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m key \u001b[39mor\u001b[39;00m util\u001b[39m.\u001b[39;49mdefault_api_key()\n\u001b[0;32m    135\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_type \u001b[39m=\u001b[39m (\n\u001b[0;32m    136\u001b[0m     ApiType\u001b[39m.\u001b[39mfrom_str(api_type)\n\u001b[0;32m    137\u001b[0m     \u001b[39mif\u001b[39;00m api_type\n\u001b[0;32m    138\u001b[0m     \u001b[39melse\u001b[39;00m ApiType\u001b[39m.\u001b[39mfrom_str(openai\u001b[39m.\u001b[39mapi_type)\n\u001b[0;32m    139\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\.conda\\envs\\openai\\lib\\site-packages\\openai\\util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[1;34m()\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAuthenticationError(\n\u001b[0;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo API key provided. You can set your API key in code using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key = <API-KEY>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key_path = <PATH>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m     )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 76\u001b[0m\n\u001b[0;32m     72\u001b[0m             pickle\u001b[39m.\u001b[39mdump(embedding_cache, embedding_cache_file)\n\u001b[0;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m embedding_cache[(text, engine)]\n\u001b[1;32m---> 76\u001b[0m a \u001b[39m=\u001b[39m get_embedding(\u001b[39m\"\u001b[39;49m\u001b[39mTwo men with heads down signing a paper.\u001b[39;49m\u001b[39m\"\u001b[39;49m, default_embedding_engine)\n\u001b[0;32m     77\u001b[0m a\n\u001b[0;32m     78\u001b[0m \u001b[39m# # create column of embeddings\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39m# for column in [\"text_1\", \"text_2\"]:\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[39m#     df_train[f\"{column}_embedding\"] = df_train[column].apply(get_embedding_with_cache)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39m# df.head()\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39m# df.to_csv(\"data/uspto_50_type_pair.csv\", index=False)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\.conda\\envs\\openai\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\.conda\\envs\\openai\\lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\.conda\\envs\\openai\\lib\\site-packages\\tenacity\\__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[0;32m    325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39mreraise()\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n\u001b[0;32m    329\u001b[0m     sleep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(retry_state)\n",
      "\u001b[1;31mRetryError\u001b[0m: RetryError[<Future at 0x23cb84c6410 state=finished raised AuthenticationError>]"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple  # for type hints\n",
    "\n",
    "import numpy as np  # for manipulating arrays\n",
    "import pandas as pd  # for manipulating data in dataframes\n",
    "import pickle  # for saving the embeddings cache\n",
    "import plotly.express as px  # for plots\n",
    "import random  # for generating run IDs\n",
    "from sklearn.model_selection import train_test_split  # for splitting train & test data\n",
    "import torch  # for matrix optimization\n",
    "\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity  # for embeddings\n",
    "\n",
    "reaction_type = {\"<RX_6>\": 0, \"<RX_2>\": 1, \"<RX_1>\": 2, \"<RX_3>\": 3, \"<RX_7>\": 4, \"<RX_9>\": 5, \"<RX_5>\": 6, \"<RX_10>\": 7, \"<RX_4>\": 8, \"<RX_8>\": 9}\n",
    "\n",
    "# input parameters\n",
    "embedding_cache_path = \"data/uspto50_embedding_cache.pkl\"  # embeddings will be saved/loaded here\n",
    "default_embedding_engine = \"babbage-similarity\"  # text-embedding-ada-002 is recommended\n",
    "num_pairs_to_embed = 1000  # 1000 is arbitrary\n",
    "local_dataset_path = \"data/uspto_50.csv\"  # download from: https://nlp.stanford.edu/projects/snli/\n",
    "train_dataset_path = \"data/uspto_50_validpair.csv\"\n",
    "test_dataset_path = \"data/uspto_50_testpair.csv\"\n",
    "\n",
    "\n",
    "def process_input_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # you can customize this to preprocess your own dataset\n",
    "    # output should be a dataframe with 3 columns: text_1, text_2, label (1 for similar, -1 for dissimilar)\n",
    "    df_temp = {\n",
    "        \"text_1\": [],\n",
    "        \"text_2\": [],\n",
    "        \"label\": [],\n",
    "    }\n",
    "    df_len = len(df)\n",
    "    for i in df_len:\n",
    "        j = i + 1\n",
    "        while j < df_len:\n",
    "            if df[\"set\"][i] == \"train\" and df[\"set\"][j] == \"train\":\n",
    "                if i < j:\n",
    "                    df_temp[\"text_1\"].append(df[\"products_mol\"][i])\n",
    "                    df_temp[\"text_2\"].append(df[\"products_mol\"][j])\n",
    "                    if df[\"reaction_type\"][i] == df[\"reaction_type\"][j]:\n",
    "                        df_temp[\"label\"].append(1)\n",
    "                    else:\n",
    "                        df_temp[\"label\"].append(-1)\n",
    "            if df[\"set\"][i] == \"test\" and df[\"set\"][j] == \"test\":\n",
    "                if i < j:\n",
    "                    df_temp[\"text_1\"].append(df[\"products_mol\"][i])\n",
    "                    df_temp[\"text_2\"].append(df[\"products_mol\"][j])\n",
    "                    if df[\"reaction_type\"][i] == df[\"reaction_type\"][j]:\n",
    "                        df_temp[\"label\"].append(1)\n",
    "                    else:\n",
    "                        df_temp[\"label\"].append(-1)\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "    # df = df.head(num_pairs_to_embed)\n",
    "    return df_temp\n",
    "\n",
    "# load data\n",
    "df_train = pd.read_csv(train_dataset_path)\n",
    "\n",
    "def get_embedding_with_cache(\n",
    "    text: str,\n",
    "    engine: str = default_embedding_engine,\n",
    "    embedding_cache: dict = df_train,\n",
    "    embedding_cache_path: str = embedding_cache_path,\n",
    ") -> list:\n",
    "    print(f\"Getting embedding for {text}\")\n",
    "    if (text, engine) not in embedding_cache.keys():\n",
    "        # if not in cache, call API to get embedding\n",
    "        embedding_cache[(text, engine)] = get_embedding(text, engine)\n",
    "        # save embeddings cache to disk after each update\n",
    "        with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "            pickle.dump(embedding_cache, embedding_cache_file)\n",
    "    return embedding_cache[(text, engine)]\n",
    "\n",
    "\n",
    "a = get_embedding(\"Two men with heads down signing a paper.\", default_embedding_engine)\n",
    "a\n",
    "# # create column of embeddings\n",
    "# for column in [\"text_1\", \"text_2\"]:\n",
    "#     df_train[f\"{column}_embedding\"] = df_train[column].apply(get_embedding_with_cache)\n",
    "\n",
    "# # create column of cosine similarity between embeddings\n",
    "# df_train[\"cosine_similarity\"] = df_train.apply(\n",
    "#     lambda row: cosine_similarity(row[\"text_1_embedding\"], row[\"text_2_embedding\"]),\n",
    "#     axis=1,\n",
    "# )\n",
    "# process input data\n",
    "# df = process_input_data(df)  # this demonstrates training data containing only positives\n",
    "# df = pd.DataFrame(df)\n",
    "# view data\n",
    "# df.head()\n",
    "# df.to_csv(\"data/uspto_50_type_pair.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
